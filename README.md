# üéôÔ∏è Speech-to-Text Benchmark Framework  

> A minimalist, extensible framework for benchmarking **ASR (automatic speech recognition)** engines and integrating post-processing / error correction modules.  
> Implements the **LIR-ASR** correction paradigm proposed in:  
> üìÑ *‚ÄúListening, Imagining & Refining: A Heuristic Optimized ASR Correction Framework with LLMs‚Äù* ([arXiv:2509.15095](https://arxiv.org/abs/2509.15095))  

![Python](https://img.shields.io/badge/python-3.9%2B-blue.svg)  
![License](https://img.shields.io/badge/license-MIT-green.svg)  
![ASR](https://img.shields.io/badge/benchmark-ASR-red.svg)  

---

## üìë Table of Contents  

- [üìÇ Datasets](#-datasets)  
- [üìä Evaluation Metrics](#-evaluation-metrics)  
- [‚öôÔ∏è Supported ASR Engines](#%EF%B8%8F-supported-asr-engines)  
- [üß© LIR-ASR Correction Framework](#-lir-asr-correction-framework)  
- [üöÄ Usage](#-usage)  
- [üìà Example / Results](#-example--results)  
- [üîß Extensions & Notes](#-extensions--notes)  
- [üìö References](#-references)  

---

## üìÇ Datasets  

The framework supports the following datasets (and can be extended easily):  

- **LibriSpeech** (test-clean / test-other)  
- **TED-LIUM**  
- **CommonVoice**  
- **Multilingual LibriSpeech (MLS)**  
- **VoxPopuli**  
- **Fleurs** (multi-language, with helper script `scripts/download_fleurs.sh`)  

---

## üìä Evaluation Metrics  

We evaluate ASR and correction performance using:  

- üìù **Word Error Rate (WER)** ‚Äî word-level edit distance / reference count  
- ‚úíÔ∏è **Punctuation Error Rate (PER)** ‚Äî errors in `.`, `,`, `?`, etc.  
- ‚è±Ô∏è **Core-Hour** ‚Äî CPU hours per 1h audio (for local models)  
- üíæ **Model Size** ‚Äî size (MB) of acoustic + language models  

> ‚ö†Ô∏è For **cloud ASR services**, Core-Hour and Model Size are **not reported**.  

---

## ‚öôÔ∏è Supported ASR Engines  

| Cloud Services         | Local / Open Models      |
|------------------------|--------------------------|
| Amazon Transcribe      | OpenAI Whisper (tiny ‚Üí large) |
| Azure Speech-to-Text   | whisper.cpp              |
| Google Speech-to-Text  | Coqui STT                |
| IBM Watson             | Custom ASR models        |
| Picovoice Cheetah      |                          |
| Picovoice Leopard      |                          |

---

## üß© LIR-ASR Correction Framework  

### üîç Overview  

**LIR-ASR (Listening ‚Üí Imagining ‚Üí Refining)** is an **iterative correction framework** inspired by how humans ‚Äúrehear‚Äù ambiguous speech.  

**Pipeline:**  
1. üëÇ **Listening** ‚Äî detect uncertain/misrecognized words  
2. üí≠ **Imagining** ‚Äî generate candidate variants (phonetic substitutions, G2P)  
3. ‚ú® **Refining** ‚Äî use LLMs / scoring models to pick the most consistent  

**Key Features:**  
- üìå **FSM Controller** ‚Äî 3 states: *NoSearch ‚Üí Search ‚Üí Search++*  
- üß≠ **Heuristic Optimization** ‚Äî rule-based semantic constraints  
- üîÑ **Iterative Refinement** ‚Äî until convergence, ensuring monotonic score improvements  

> ‚úÖ Achieves **~1.5% CER/WER improvements** on average over uncorrected baselines.  

---

## üöÄ Usage  

### üîß Setup  

```bash
# Install dependencies
pip3 install -r requirements.txt

# Prepare datasets
sh scripts/download_fleurs.sh  # example for Fleurs
```

### üìù Example: RIF-ASR Optimization
```
from optim import prompt_optimization, evolutionary_prompt_optimization, nbest_optimization, RIF_ASR
from normalizer import Normalizer
from languages import Languages

# Init normalizer
norm = Normalizer.create(language=Languages.EN, keep_punctuation=True, punctuation_set=".?")

asr_text = "THE CAT SAT ON THE MAT"

# 1. Prompt optimization
corrected = prompt_optimization(asr_text, llm="DeepSeek-V3.1")

# 2. Evolutionary optimization
refined = evolutionary_prompt_optimization(asr_text, llm="DeepSeek-V3.1")

# 3. RIF-ASR with multiple candidates
candidates = ["THE CAT SAT ON THE MAT", "THE CAT SAT ON THE HAT", "THE CAT SAT ON THE RAT"]
result = RIF_ASR(candidates, llm="Qwen3-235B", language="EN", normalizer=norm)
```

### üèÉ Running Benchmarks
```
sh scripts/evaluation_whisper_qwen.sh
```

### üìö References
```
@misc{liu2025listeningimaginingrefining,
      title={Listening, Imagining & Refining: A Heuristic Optimized ASR Correction Framework with LLMs}, 
      author={Yutong Liu and Ziyue Zhang and Cheng Huang and Yongbin Yu and Xiangxiang Wang and Yuqing Cai and Nyima Tashi},
      year={2025},
      eprint={2509.15095},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2509.15095}, 
}
```